p8105\_hw3\_dw2903
================
Di Wu dw2903
2019/10/12

## Problem 1

``` r
nrow(count(instacart,aisle))
```

    ## [1] 134

``` r
instacart %>%
  group_by(aisle) %>%
  summarize(n=n()) %>%
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

There are 134 aisles in this dataset and the aisle that most order from
is fresh vegetables

``` r
instacart %>% 
  count(aisle)%>%
  filter(n>10000) %>%
  arrange(desc(n))%>%
  ggplot(aes(y=n, color=aisle))+geom_boxplot()
```

![](p8105_hw3_dw2903_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

``` r
baking = 
  instacart %>%
  filter(
    aisle == "baking ingredients")%>%
  group_by(product_name)%>%
  count()%>%
  arrange(desc(n))
dog_food = 
  instacart %>%
  filter(
    aisle == "dog food care")%>%
  group_by(product_name)%>%
  count()%>%
  arrange(desc(n))
vege = 
  instacart %>%
  filter(
    aisle == "packaged vegetables fruits")%>%
  group_by(product_name)%>%
  count()%>%
  arrange(desc(n))
```

``` r
rbind(
  baking=baking[c(1:3),c(1:2)],
  dog_food=dog_food[c(1:3),c(1:2)],
  vege=vege[c(1:3),c(1:2)])
```

    ## # A tibble: 9 x 2
    ## # Groups:   product_name [9]
    ##   product_name                                      n
    ##   <chr>                                         <int>
    ## 1 Light Brown Sugar                               499
    ## 2 Pure Baking Soda                                387
    ## 3 Cane Sugar                                      336
    ## 4 Snack Sticks Chicken & Rice Recipe Dog Treats    30
    ## 5 Organix Chicken & Brown Rice Recipe              28
    ## 6 Small Dog Biscuits                               26
    ## 7 Organic Baby Spinach                           9784
    ## 8 Organic Raspberries                            5546
    ## 9 Organic Blueberries                            4966

``` r
instacart %>%
  filter(product_name %in% c("Pink Lady Apple","Coffee Ice Cream"))%>%
  group_by(product_name, order_dow)%>%
  summarize(
    mean_order_hour_of_day = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = product_name,
    values_from = mean_order_hour_of_day
  )
```

    ## # A tibble: 7 x 3
    ##   order_dow `Coffee Ice Cream` `Pink Lady Apple`
    ##       <int>              <dbl>             <dbl>
    ## 1         0               13.8              14.4
    ## 2         1               14.3              14.2
    ## 3         2               15.4              13.2
    ## 4         3               15.3               8  
    ## 5         4               15.2              11  
    ## 6         5               12.3              16  
    ## 7         6               13.8              13

## Problem 2

``` r
brfss_adj=
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health",
         response %in% c("Excellent","Poor")) %>%
  arrange(.,desc(response))
```

    ## Warning in FUN(X[[i]], ...): strings not representable in native encoding
    ## will be translated to UTF-8

``` r
brfss_adj
```

    ## # A tibble: 4,250 x 23
    ##     year locationabbr locationdesc class topic question response
    ##    <int> <chr>        <chr>        <chr> <chr> <chr>    <chr>   
    ##  1  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Poor    
    ##  2  2010 AL           AL - Mobile~ Heal~ Over~ How is ~ Poor    
    ##  3  2010 AL           AL - Tuscal~ Heal~ Over~ How is ~ Poor    
    ##  4  2010 AZ           AZ - Marico~ Heal~ Over~ How is ~ Poor    
    ##  5  2010 AZ           AZ - Pima C~ Heal~ Over~ How is ~ Poor    
    ##  6  2010 AZ           AZ - Pinal ~ Heal~ Over~ How is ~ Poor    
    ##  7  2010 AR           AR - Benton~ Heal~ Over~ How is ~ Poor    
    ##  8  2010 AR           AR - Pulask~ Heal~ Over~ How is ~ Poor    
    ##  9  2010 AR           AR - Washin~ Heal~ Over~ How is ~ Poor    
    ## 10  2010 CA           CA - Alamed~ Heal~ Over~ How is ~ Poor    
    ## # ... with 4,240 more rows, and 16 more variables: sample_size <int>,
    ## #   data_value <dbl>, confidence_limit_low <dbl>,
    ## #   confidence_limit_high <dbl>, display_order <int>,
    ## #   data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

``` r
brfss_adj %>%
  filter(
    year == 2002) %>%
  group_by(year,locationabbr) %>%
  count()%>%
  filter(n>=7)
```

    ## # A tibble: 17 x 3
    ## # Groups:   year, locationabbr [17]
    ##     year locationabbr     n
    ##    <int> <chr>        <int>
    ##  1  2002 CO               8
    ##  2  2002 CT              14
    ##  3  2002 FL              14
    ##  4  2002 HI               8
    ##  5  2002 MA              16
    ##  6  2002 MD              12
    ##  7  2002 MI               8
    ##  8  2002 MN               8
    ##  9  2002 NC              14
    ## 10  2002 NH              10
    ## 11  2002 NJ              16
    ## 12  2002 NY              10
    ## 13  2002 OH               8
    ## 14  2002 PA              20
    ## 15  2002 RI               8
    ## 16  2002 UT              10
    ## 17  2002 WA               8

``` r
brfss_adj %>%
  filter(
    year == 2010) %>%
  group_by(year,locationabbr) %>%
  count()%>%
  filter(n>=7)
```

    ## # A tibble: 30 x 3
    ## # Groups:   year, locationabbr [30]
    ##     year locationabbr     n
    ##    <int> <chr>        <int>
    ##  1  2010 CA              24
    ##  2  2010 CO              14
    ##  3  2010 CT              10
    ##  4  2010 FL              82
    ##  5  2010 GA               8
    ##  6  2010 HI               8
    ##  7  2010 ID              12
    ##  8  2010 KS               8
    ##  9  2010 LA              10
    ## 10  2010 MA              18
    ## # ... with 20 more rows

``` r
brfss_adj %>%
  filter(response == "Excellent") %>%
  select(year, locationabbr, data_value) %>%
  group_by(year,locationabbr) %>%
  summarize(
    mean_data_value = mean(data_value)
   )%>%
  ggplot(aes(x=year, y=mean_data_value, color = locationabbr))+geom_line()
```

    ## Warning: Removed 3 rows containing missing values (geom_path).

![](p8105_hw3_dw2903_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

``` r
brfss_06=
brfss_adj %>%
  filter(year == 2006) %>%
  group_by(locationabbr,response)%>%
  summarize(
    mean_data_value = mean(data_value)
  )%>%
  ggplot(aes(x=locationabbr,y=mean_data_value, color=response))+geom_point()

brfss_10=
brfss_adj %>%
  filter(year == 2010) %>%
  group_by(locationabbr,response)%>%
  summarize(
    mean_data_value = mean(data_value)
  )%>%
  ggplot(aes(x=locationabbr,y=mean_data_value, color=response))+geom_point()
brfss_06/ brfss_10
```

    ## Warning: Removed 1 rows containing missing values (geom_point).

    ## Warning: Removed 2 rows containing missing values (geom_point).

![](p8105_hw3_dw2903_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->
\#\# Problem 3

``` r
accel_data = 
  read.csv("./accel_data.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity"
  ) %>%
  mutate(
    weekend =case_when(
      day_id %in% c(3,4) ~"weekend",
      day_id %in% c(1,2,5,6,7) ~"weekday"
    )
  )
accel_data
```

    ## # A tibble: 50,400 x 6
    ##     week day_id day    minute activity weekend
    ##    <int>  <int> <fct>  <chr>     <dbl> <chr>  
    ##  1     1      1 Friday 1          88.4 weekday
    ##  2     1      1 Friday 2          82.2 weekday
    ##  3     1      1 Friday 3          64.4 weekday
    ##  4     1      1 Friday 4          70.0 weekday
    ##  5     1      1 Friday 5          75.0 weekday
    ##  6     1      1 Friday 6          66.3 weekday
    ##  7     1      1 Friday 7          53.8 weekday
    ##  8     1      1 Friday 8          47.8 weekday
    ##  9     1      1 Friday 9          55.5 weekday
    ## 10     1      1 Friday 10         43.0 weekday
    ## # ... with 50,390 more rows

In the tidy version of the data frame, the week, week\_id and minute
variable indicate the date and time of the point measure, and the day
and weekend variable showing which day it is and whether it is weekend

``` r
accel_data %>%
  group_by(week,day)%>%
  summarize(
    total_activity = sum(activity)
  ) 
```

    ## # A tibble: 35 x 3
    ## # Groups:   week [5]
    ##     week day       total_activity
    ##    <int> <fct>              <dbl>
    ##  1     1 Friday           480543.
    ##  2     1 Monday            78828.
    ##  3     1 Saturday         376254 
    ##  4     1 Sunday           631105 
    ##  5     1 Thursday         355924.
    ##  6     1 Tuesday          307094.
    ##  7     1 Wednesday        340115.
    ##  8     2 Friday           568839 
    ##  9     2 Monday           295431 
    ## 10     2 Saturday         607175 
    ## # ... with 25 more rows

As showing in the total activity over the day, from Monday to Sunday
generally increased as day passing and then decreased after around 1
weak. this pattern repeat as day passing.

``` r
accel_data %>%
  ggplot(aes(x=minute, y = activity, color=day_id))+geom_point()
```

![](p8105_hw3_dw2903_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

for every day activity, the activity increased slighly and reach the
maximum at around 500 minutes and slightly decrease until reac the
bottom around 600, and then increased again at around 800 minutes to the
second peak of day and then rest to stable.
